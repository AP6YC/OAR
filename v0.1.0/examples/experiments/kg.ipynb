{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This script demonstrates the usage of a START module for analyzing biomedical data knowledge graphs.\n",
    "Though the `OAR` project contains multiple such knowledge graphs, the Charcot-Marie-Tooth (CMT) dataset is used as an example here with the procedure remaining the same with other datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we load some dependencies:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Import the OAR project module\n",
    "using OAR"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we must should point to the location of the dataset containing the preprocessed knowledge graph statements"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"../assets/edge_attributes_lerche.txt\""
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "# Location of the edge attributes file, formatted for Lerch parsing\n",
    "edge_file = joinpath(\"..\", \"assets\", \"edge_attributes_lerche.txt\")"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the KG statements"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Vector{Vector{GSymbol{String}}}\u001b[90m (alias for \u001b[39m\u001b[90mArray{Array{GSymbol{String}, 1}, 1}\u001b[39m\u001b[90m)\u001b[39m"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "statements = OAR.get_kg_statements(edge_file)\n",
    "typeof(statements)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate a simple subject-predicate-object grammar from the statements"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OAR.CFG{String}(N:3, S:3, P:3, T:788)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "grammar = OAR.SPOCFG(statements)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize the START module"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "START(ProtoNode[], OAR.CFG{String}(N:3, S:3, P:3, T:788), OAR.opts_START\n  rho: Float64 0.05\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  epochs: Int64 1\n  terminated: Bool false\n, Int64[], Float64[], Float64[], Dict{String, Any}(\"n_categories\" => 0, \"n_clusters\" => 0, \"n_instance\" => Int64[]))"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "gramart = OAR.START(\n",
    "    grammar,\n",
    "    rho=0.05,\n",
    "    terminated=false,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are ready to cluster the statements.\n",
    "We do this with the `train!` function without supervised labels, indicating that we are learning on the samples alone."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Process the statements\n",
    "for statement in statements\n",
    "    OAR.train!(gramart, statement)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see how the clustering went by inspecting how many clusters we generated:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Number of categories: 6\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "@info \"Number of categories: $(length(gramart.protonodes))\""
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example demonstrates the usage of a GramART module.\n",
    "This module is tested on a modified symbolic Iris dataset as a proof of concept, but it is capable of working on arbitrary symbolic datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we load some dependencies:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Import the OAR project module\n",
    "using OAR"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can load the Iris dataset in a modified symbolic form:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(OAR.VectoredDataSplit{GSymbol{String}, Int64}: dim=4, n_train=105, n_test=45:\ntrain_x: (105,) Vector{Vector{GSymbol{String}}}\ntest_x: (45,) Vector{Vector{GSymbol{String}}}\ntrain_y: (105,) Vector{Int64}\ntest_y: (45,) Vector{Int64}\n, OAR.CFG{String}(N:4, S:4, P:4, T:40))"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "# All-in-one function\n",
    "fs, bnf = OAR.symbolic_iris()"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can finally initialize the GramART module using the grammar that we have describing the symbolic Iris dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GramART(ProtoNode[], OAR.CFG{String}(N:4, S:4, P:4, T:40), OAR.opts_GramART\n  rho: Float64 0.7\n  rho_lb: Float64 0.55\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  max_epoch: Int64 1\n  terminated: Bool false\n, Int64[], Dict{String, Any}(\"n_categories\" => 0, \"n_clusters\" => 0, \"n_instance\" => Int64[]))"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "# Initialize the GramART module\n",
    "gramart = OAR.GramART(bnf)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have a GramART module, we should process the training dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Cluster the statements\n",
    "for statement in fs.train_x\n",
    "    OAR.train!(gramart, statement)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "In fact, we can also do a simple supervised version of the training if labels are available.\n",
    "Let's do that with another module:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Initialize the GramART module\n",
    "gramart_supervised = OAR.GramART(bnf)\n",
    "# Set the vigilance low for generalization\n",
    "gramart_supervised.opts.rho = 0.05\n",
    "# Train in supervised mode\n",
    "for ix in eachindex(fs.train_x)\n",
    "    sample = fs.train_x[ix]\n",
    "    label = fs.train_y[ix]\n",
    "    OAR.train!(gramart_supervised, sample, y=label)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's see what's inside the first module:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Number of categories: 50\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "# Inspect the module\n",
    "@info \"Number of categories: $(length(gramart.protonodes))\""
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also see how the supervised training went by classifying the test data and computing the performance:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Supervised testing performance: 0.9555555555555556\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "# Classification\n",
    "y_hat = zeros(Int, length(fs.test_y))\n",
    "for ix in eachindex(fs.test_x)\n",
    "    sample = fs.test_x[ix]\n",
    "    y_hat[ix] = OAR.classify(gramart_supervised, sample, get_bmu=true)\n",
    "end\n",
    "\n",
    "# Calculate performance\n",
    "perf = OAR.AdaptiveResonance.performance(y_hat, fs.test_y)\n",
    "@info \"Supervised testing performance: $(perf)\""
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
